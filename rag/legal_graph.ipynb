{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "neo4j-graphrag 1.6.1 requires json-repair<0.40.0,>=0.39.1, but you have json-repair 0.41.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-community openai langchain-experimental neo4j tiktoken yfiles_jupyter_graphs python-dotenv json-repair langchain-openai langchain_core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import  RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from neo4j import GraphDatabase\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "import os\n",
    "from neo4j import  Driver\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener variables de entorno\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_deployment = os.getenv(\"GPT_ENGINE\")\n",
    "api_version = os.getenv(\"API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(url=\"neo4j://localhost:7688\", username=\"neo4j\", password=\"your_password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf2 in c:\\users\\exequielsilvestre\\desktop\\cursos\\legal-graphrag\\rag\\venv\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\exequielsilvestre\\desktop\\cursos\\legal-graphrag\\rag\\venv\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\exequielsilvestre\\desktop\\cursos\\legal-graphrag\\rag\\venv\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\exequielsilvestre\\desktop\\cursos\\legal-graphrag\\rag\\venv\\lib\\site-packages (11.2.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\exequielsilvestre\\desktop\\cursos\\legal-graphrag\\rag\\venv\\lib\\site-packages (from pytesseract) (24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pypdf2 pytesseract pdf2image pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\ExequielSilvestre\\AppData\\Local\\Temp\\ipykernel_39900\\3851376376.py:2: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  os.environ['TESSDATA_PREFIX'] = \"C:\\Program Files\\Tesseract-OCR\"\n",
      "C:\\Users\\ExequielSilvestre\\AppData\\Local\\Temp\\ipykernel_39900\\3851376376.py:2: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  os.environ['TESSDATA_PREFIX'] = \"C:\\Program Files\\Tesseract-OCR\"\n"
     ]
    },
    {
     "ename": "TesseractError",
     "evalue": "(1, 'Error opening data file C:\\\\Program Files\\\\Tesseract-OCR/spa.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'spa\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTesseractError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pages:\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     text += \u001b[43mpytesseract\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mspa\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(text[:\u001b[32m1000\u001b[39m])  \u001b[38;5;66;03m# Mostramos los primeros caracteres para verificar\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ExequielSilvestre\\Desktop\\Cursos\\legal-graphrag\\rag\\venv\\Lib\\site-packages\\pytesseract\\pytesseract.py:486\u001b[39m, in \u001b[36mimage_to_string\u001b[39m\u001b[34m(image, lang, config, nice, output_type, timeout)\u001b[39m\n\u001b[32m    481\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    484\u001b[39m args = [image, \u001b[33m'\u001b[39m\u001b[33mtxt\u001b[39m\u001b[33m'\u001b[39m, lang, config, nice, timeout]\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBYTES\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDICT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSTRING\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ExequielSilvestre\\Desktop\\Cursos\\legal-graphrag\\rag\\venv\\Lib\\site-packages\\pytesseract\\pytesseract.py:489\u001b[39m, in \u001b[36mimage_to_string.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    481\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    484\u001b[39m args = [image, \u001b[33m'\u001b[39m\u001b[33mtxt\u001b[39m\u001b[33m'\u001b[39m, lang, config, nice, timeout]\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    487\u001b[39m     Output.BYTES: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(*(args + [\u001b[38;5;28;01mTrue\u001b[39;00m])),\n\u001b[32m    488\u001b[39m     Output.DICT: \u001b[38;5;28;01mlambda\u001b[39;00m: {\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m: run_and_get_output(*args)},\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     Output.STRING: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    490\u001b[39m }[output_type]()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ExequielSilvestre\\Desktop\\Cursos\\legal-graphrag\\rag\\venv\\Lib\\site-packages\\pytesseract\\pytesseract.py:352\u001b[39m, in \u001b[36mrun_and_get_output\u001b[39m\u001b[34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m save(image) \u001b[38;5;28;01mas\u001b[39;00m (temp_name, input_filename):\n\u001b[32m    342\u001b[39m     kwargs = {\n\u001b[32m    343\u001b[39m         \u001b[33m'\u001b[39m\u001b[33minput_filename\u001b[39m\u001b[33m'\u001b[39m: input_filename,\n\u001b[32m    344\u001b[39m         \u001b[33m'\u001b[39m\u001b[33moutput_filename_base\u001b[39m\u001b[33m'\u001b[39m: temp_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    349\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m: timeout,\n\u001b[32m    350\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     \u001b[43mrun_tesseract\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_output(\n\u001b[32m    354\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[33m'\u001b[39m\u001b[33moutput_filename_base\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextsep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    355\u001b[39m         return_bytes,\n\u001b[32m    356\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ExequielSilvestre\\Desktop\\Cursos\\legal-graphrag\\rag\\venv\\Lib\\site-packages\\pytesseract\\pytesseract.py:284\u001b[39m, in \u001b[36mrun_tesseract\u001b[39m\u001b[34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[39m\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m timeout_manager(proc, timeout) \u001b[38;5;28;01mas\u001b[39;00m error_string:\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m proc.returncode:\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m TesseractError(proc.returncode, get_errors(error_string))\n",
      "\u001b[31mTesseractError\u001b[39m: (1, 'Error opening data file C:\\\\Program Files\\\\Tesseract-OCR/spa.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'spa\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Usar una cadena cruda (raw string) para la ruta\n",
    "os.environ['TESSDATA_PREFIX'] = r\"C:\\Program Files\\Tesseract-OCR\"\n",
    "\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "# Asegúrate de poner tu ruta real si no agregaste Tesseract al PATH\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Ruta al PDF escaneado\n",
    "pdf_path = './material/RTF 01640-4-2010 - Causalidad de gasto.pdf'\n",
    "\n",
    "# Convertir el PDF a imágenes\n",
    "pages = convert_from_path(pdf_path, dpi=300)\n",
    "\n",
    "# Aplicar OCR\n",
    "text = \"\"\n",
    "for page in pages:\n",
    "    text += pytesseract.image_to_string(page, lang='spa')\n",
    "\n",
    "print(text[:1000])  # Mostramos los primeros caracteres para verificar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extracted from: RTF 01640-4-2010 - Causalidad de gasto.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "\n",
    "reviews_folder = \"./material\"\n",
    "documents = []\n",
    "\n",
    "# Verifica si la carpeta existe\n",
    "if os.path.isdir(reviews_folder):\n",
    "    for filename in os.listdir(reviews_folder):\n",
    "        file_path = os.path.join(reviews_folder, filename)\n",
    "\n",
    "        # Verifica si el archivo es un PDF\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            try:\n",
    "                with open(file_path, \"rb\") as f:\n",
    "                    reader = PyPDF2.PdfReader(f)\n",
    "                    text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "                    documents.append({\"filename\": filename, \"content\": text})\n",
    "                    print(f\"Text extracted from: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "else:\n",
    "    print(f\"The folder '{reviews_folder}' does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RTF 01640-4-2010 - Causalidad de gasto.pdf - Length of content: 0\n"
     ]
    }
   ],
   "source": [
    "for doc in documents:\n",
    "    print(f\"{doc['filename']} - Length of content: {len(doc['content'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Configurar el splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=24)\n",
    "\n",
    "# Convertir los documentos en chunks\n",
    "chunked_documents = []\n",
    "for doc in documents:\n",
    "    chunks = text_splitter.split_text(doc[\"content\"])\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunked_documents.append(Document(page_content=chunk, metadata={\"filename\": doc[\"filename\"], \"chunk_id\": i + 1}))\n",
    "\n",
    "print(len(chunked_documents))\n",
    "print(chunked_documents[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import SystemMessage\n",
    "\n",
    "\n",
    "# # Definir los nodos y relaciones permitidos para la extracción de información\n",
    "allowed_nodes = [\"Patient\", \"Disease\", \"Medication\", \"Test\", \"Symptom\", \"Doctor\"]\n",
    "allowed_relationships = [\"HAS_DISEASE\", \"TAKES_MEDICATION\", \"UNDERWENT_TEST\", \"HAS_SYMPTOM\", \"TREATED_BY\"]\n",
    "\n",
    "\n",
    "# Configurar Azure OpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    openai_api_key=azure_api_key,\n",
    "    azure_deployment=azure_deployment,\n",
    "    model=azure_deployment,  \n",
    "    api_version=api_version,  \n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Configurar el transformador de gráficos con el prompt\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=allowed_nodes,\n",
    "    allowed_relationships=allowed_relationships,\n",
    ")\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(chunked_documents[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphDocument(nodes=[Node(id='Stomach Cancer', type='Disease', properties={}), Node(id='JOHN MULLEN, MD', type='Doctor', properties={}), Node(id='A 76-year-old woman', type='Patient', properties={}), Node(id='adenocarcinoma of the body of the stomach', type='Disease', properties={})], relationships=[Relationship(source=Node(id='A 76-year-old woman', type='Patient', properties={}), target=Node(id='Stomach Cancer', type='Disease', properties={}), type='HAS_DISEASE', properties={}), Relationship(source=Node(id='A 76-year-old woman', type='Patient', properties={}), target=Node(id='adenocarcinoma of the body of the stomach', type='Disease', properties={}), type='HAS_DISEASE', properties={}), Relationship(source=Node(id='JOHN MULLEN, MD', type='Doctor', properties={}), target=Node(id='A 76-year-old woman', type='Patient', properties={}), type='TREATED_BY', properties={})], source=Document(metadata={'filename': 'gastroesophageal-surgery-case-scenario-stomach-cancer-mullen.pdf', 'chunk_id': 1}, page_content='A 76-Year-Old Woman  \\nwith Stomach Cancer\\nJOHN MULLEN, MD\\nMassachusetts General Hospital\\nPRESENTATION OF CASE\\nA 76-year-old woman was seen in our \\nmultidisciplinary gastrointestinal oncology clinic for further management of an adenocarcinoma of the body of the stomach. \\nThe patient presented to her primary care'))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resetear el grafo en caso de ser necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph database cleared successfully.\n",
      "Node count: 0, Relationship count: 0\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Conectar a la base de datos Neo4j\n",
    "driver = GraphDatabase.driver(uri=\"neo4j://localhost:7688\", auth=(\"neo4j\", \"your_password\"))\n",
    "\n",
    "# Función para limpiar el grafo\n",
    "def clear_graph(tx):\n",
    "    tx.run(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "# Función para comprobar si el grafo está vacío (contar nodos y relaciones)\n",
    "def check_empty_graph(tx):\n",
    "    # Contar tanto los nodos como las relaciones\n",
    "    result = tx.run(\"MATCH (n) OPTIONAL MATCH (n)-[r]->() RETURN count(n) AS node_count, count(r) AS relationship_count\")\n",
    "    for record in result:\n",
    "        return record[\"node_count\"], record[\"relationship_count\"]\n",
    "\n",
    "# Ejecutar la limpieza del grafo\n",
    "def execute_clear_graph():\n",
    "    with driver.session() as session:\n",
    "        session.execute_write(clear_graph)\n",
    "        print(\"Graph database cleared successfully.\")\n",
    "\n",
    "# Ejecutar la comprobación del estado del grafo\n",
    "def execute_check_empty_graph():\n",
    "    with driver.session() as session:\n",
    "        node_count, relationship_count = session.execute_read(check_empty_graph)\n",
    "        print(f\"Node count: {node_count}, Relationship count: {relationship_count}\")\n",
    "\n",
    "# Limpiar el grafo y luego verificar\n",
    "execute_clear_graph()          # Limpiar el grafo\n",
    "execute_check_empty_graph()    # Verificar que está vacío\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(\n",
    "    graph_documents,\n",
    "    baseEntityLabel=True,\n",
    "    include_source=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ede237d951e4a77b87a02978e23d3e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='800px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def showGraph():\n",
    "    driver = GraphDatabase.driver(\n",
    "        uri = \"neo4j://localhost:7688\",\n",
    "        auth = (os.getenv(\"NEO4J_USERNAME\"),\n",
    "                os.getenv(\"NEO4J_PASSWORD\"))\n",
    "    )\n",
    "    session = driver.session()\n",
    "    widget = GraphWidget(graph=session.run(\"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t\").graph())\n",
    "    widget.node_label_mapping = 'id'\n",
    "    return widget\n",
    "\n",
    "showGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "# Configurar Embeddings de Azure OpenAI\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_KEY\"), \n",
    "    azure_endpoint=\"https://rag-esilvestre.openai.azure.com\", \n",
    "    deployment=\"text-embedding-ada-002\", \n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_version=\"2023-07-01-preview\"\n",
    ")\n",
    "\n",
    "# Crear índice vectorial en Neo4j\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings,\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\",\n",
    "    url=\"neo4j://localhost:7688\",\n",
    "    username=\"neo4j\",\n",
    "    password=\"your_password\",\n",
    ")\n",
    "\n",
    "# Convertir el índice en un Retriever\n",
    "vector_retriever = vector_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(\n",
    "        uri = \"neo4j://localhost:7688\", \n",
    "        auth = (os.getenv(\"NEO4J_USERNAME\"),\n",
    "                os.getenv(\"NEO4J_PASSWORD\"))\n",
    "    )\n",
    "\n",
    "def create_fulltext_index(tx):\n",
    "    query = '''\n",
    "    CREATE FULLTEXT INDEX `fulltext_entity_id` \n",
    "    FOR (n:__Entity__) \n",
    "    ON EACH [n.id];\n",
    "    '''\n",
    "    tx.run(query)\n",
    "\n",
    "# Function to execute the query\n",
    "def create_index():\n",
    "    with driver.session() as session:\n",
    "        session.execute_write(create_fulltext_index)\n",
    "        print(\"Fulltext index created successfully.\")\n",
    "\n",
    "# Call the function to create the index\n",
    "try:\n",
    "    create_index()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Close the driver connection\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "\n",
    "# Configurar Azure OpenAI\n",
    "llmGraph= AzureChatOpenAI(\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    openai_api_key=azure_api_key,\n",
    "    azure_deployment=azure_deployment,\n",
    "    model=azure_deployment,\n",
    "    api_version=api_version,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "\n",
    "# Usar GraphCypherQAChain para integrar las consultas al gráfico y la LLM\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    llmGraph,\n",
    "    graph=graph,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True,\n",
    "    validate_cypher=True\n",
    ")\n",
    "\n",
    "# Función para hacer las preguntas all llm contra el graph\n",
    "def ask_question(query):\n",
    "    response = chain.invoke({\"query\": query})\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que ocurre por detras:\n",
    "1. Conuslta el schema del grafo, de esta forma puede encontrar una query adecuada\n",
    "2. Genera la consulta cypher.\n",
    "3. Realiza una valdiaciòn de la conuslta cypher_query_corrector.\n",
    "4. Ejecuta la consulta contra el grafo.\n",
    "5. Una ultima consulta a un llm para obtener el reusltado final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (m:Medication) RETURN m\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'m': {'id': 'Paxil'}}, {'m': {'id': 'lisinopril'}}, {'m': {'id': 'metformin'}}, {'m': {'id': 'Inderal'}}, {'m': {'id': 'omeprazole'}}, {'m': {'id': 'atorvastatin'}}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'List all the medications',\n",
       " 'result': 'The medications listed are Paxil, lisinopril, metformin, Inderal, omeprazole, and atorvastatin.'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_question(\"List all the medications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_retriever(query: str):\n",
    "    graph_data = ask_question(query)\n",
    "    vector_data = [el.page_content for el in vector_retriever.invoke(query)]\n",
    "    final_data = f\"\"\"Graph data:\n",
    "{graph_data}\n",
    "vector data:\n",
    "{\"#Document \".join(vector_data)}\n",
    "    \"\"\"\n",
    "    print(final_data)\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_final_answer = AzureChatOpenAI(\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    openai_api_key=azure_api_key,\n",
    "    azure_deployment=azure_deployment,\n",
    "    model=azure_deployment,\n",
    "    api_version=api_version,\n",
    "    temperature= 0\n",
    ")\n",
    "\n",
    "final_prompt_structure = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are AI assistant and you will answers questions using graph data and the vector data.\"),\n",
    "        (\"human\", \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "Use natural language and be concise.\n",
    "Answer:\"\"\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 3. Crea una función simple para procesar la entrada\n",
    "def process_input(query):\n",
    "    # Obtener el contexto usando el retriever\n",
    "    context = full_retriever(query)\n",
    "    \n",
    "    # Preparar los datos para el prompt\n",
    "    data = {\n",
    "        \"context\": context,\n",
    "        \"query\": query\n",
    "    }\n",
    "\n",
    "    final_prompt = final_prompt_structure.format(**data)\n",
    "    response = llm_final_answer.invoke(final_prompt)\n",
    "    return response.text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (d:Disease) RETURN d\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'d': {'id': 'moderately to poorly differentiated adenocarcinoma'}}, {'d': {'id': 'type 2 diabetes'}}, {'d': {'id': 'hypertension'}}, {'d': {'id': 'Stomach Cancer'}}, {'d': {'id': 'adenocarcinoma of the body of the stomach'}}, {'d': {'id': 'ulcerated tumor in the body of the stomach'}}, {'d': {'id': 'H. pylori infection'}}, {'d': {'id': 'elevated lipids'}}, {'d': {'id': 'anxiety'}}, {'d': {'id': 'II diabetes mellitus'}}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph data:\n",
      "{'query': 'List the diseases', 'result': 'The diseases listed are moderately to poorly differentiated adenocarcinoma, type 2 diabetes, hypertension, stomach cancer, adenocarcinoma of the body of the stomach, ulcerated tumor in the body of the stomach, H. pylori infection, elevated lipids, anxiety, and II diabetes mellitus.'}\n",
      "vector data:\n",
      "\n",
      "text: examination of biopsy specimens of the stomach ulcer showed moderately to poorly differentiated adenocarcinoma. Staging computed tomography (CT) scans of the chest, abdomen and pelvis only showed prominent lymph nodes adjacent to the lesser curvature of the stomach within the gastrohepatic ligament and no evidence of metastatic disease.#Document \n",
      "text: II diabetes mellitus, hypertension, elevated lipids, gastroesophageal reflux disease (GERD), diverticulosis, endometriosis, kidney stones, anxiety and osteopenia. Her medications included atorvastatin, Inderal, lisinopril, metformin, omeprazole and Paxil. She had allergies to dyazide, morphine, intravenous contrast dye, aspirin and triamcinolone cream. She was a retired research assistant and was married with two children. She never smoked and did not drink alcohol. There was no family history of stomach#Document \n",
      "text: history of stomach cancer, but her older brother died of colon cancer metastatic to the liver and lung at the age of 90.#Document \n",
      "text: Upon evaluation at our cancer center, she reported \n",
      "intermittent upper abdominal discomfort that was worse without food but was typically relieved with eating. She denied any change in appetite or weight. She had no nausea, vomiting, early satiety or change in her bowel habits. \n",
      "Her past medical history was notable for type\n",
      "    \n",
      "--------FINAL ANSWER--------\n",
      "The diseases listed are moderately to poorly differentiated adenocarcinoma, type 2 diabetes, hypertension, stomach cancer, adenocarcinoma of the body of the stomach, ulcerated tumor in the body of the stomach, H. pylori infection, elevated lipids, anxiety, and II diabetes mellitus.\n"
     ]
    }
   ],
   "source": [
    "query = \"List the diseases\"\n",
    "response = process_input(query)\n",
    "print(\"--------FINAL ANSWER--------\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
